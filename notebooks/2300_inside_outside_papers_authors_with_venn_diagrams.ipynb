{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8e7c4a-db4d-4dd2-8f8d-86bfd7a1c1a6",
   "metadata": {},
   "source": [
    "# Inside/Outside Papers\n",
    "The main aim of this notebook is to classify RS papers as being from the inside community or the outside community, as defined in the ToRS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be619b3d-cb3c-4431-830f-88d501ff7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import string \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Stemmer\n",
    "\n",
    "import random\n",
    "import requests\n",
    "from itertools import chain\n",
    "from more_itertools import sliced\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.pylab import plt\n",
    "from matplotlib_venn import venn2, venn3, venn2_circles, venn3_circles\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "                         \n",
    "from loguru import logger\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from itables import init_notebook_mode, show, options\n",
    "init_notebook_mode(all_interactive=False)\n",
    "\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1907cfc4-3b82-43d6-a58e-bae03bf8d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=1.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2317520-ca0e-49eb-8a82-6078d63934f7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376673-62b2-483b-8142-c6e44c0daa61",
   "metadata": {},
   "source": [
    "## Load the Papers and Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72167b9-0377-4dc6-bf80-f5ebad2253e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_dataset = '../data/processed/2200_recsys_papers_cleaned.feather'\n",
    "papers_df = pd.read_feather(papers_dataset)\n",
    "papers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624e6be-14db-4ecd-92cb-74642d6ba66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_dataset = '../data/processed/2200_recsys_authors_cleaned.feather'\n",
    "authors_df = pd.read_feather(authors_dataset)\n",
    "authors_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86440121-1953-4f1b-9190-76a9e02a2bdf",
   "metadata": {},
   "source": [
    "## Get Core RecSys Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e95bf-bb39-4b80-9f31-33607ed51462",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_recsys_paper = papers_df['is_core_recsys_paper']\n",
    "\n",
    "recsys_papers_df = papers_df[is_recsys_paper ].copy()\n",
    "recsys_author_ids = set(recsys_papers_df['authors'].explode().dropna().unique())\n",
    "\n",
    "len(recsys_author_ids), recsys_papers_df.shape, is_recsys_paper.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5b723-a924-4cf2-9f68-a6e68d3764c0",
   "metadata": {},
   "source": [
    "## Define the Venue Papers\n",
    "These are the subset of papers that are published in the main RS venues (ACM RecSys, ACM ToRS, and the various long-running ACM RecSys workshops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27143ad2-f2f2-41df-bd28-02b02228e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_venues = ['acm recsys', 'intrsrecsys', 'recsys poster', 'rectourrecsys', 'recsys challenge']\n",
    "in_recsys_venue = recsys_papers_df['venue'].map(lambda venue: venue.lower()).isin(recsys_venues)\n",
    "\n",
    "recsys_papers_df['is_venue_paper'] = recsys_papers_df['has_recsys_key'] | recsys_papers_df['clean_venue'].isin(recsys_venues)\n",
    "\n",
    "recsys_papers_df['is_venue_paper'].sum(), recsys_papers_df['has_recsys_key'].sum(), recsys_papers_df['clean_venue'].isin(recsys_venues).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e6b0c-d25c-4184-b9d8-fdf638a19417",
   "metadata": {},
   "source": [
    "# The Papers/Authors Venn Diagrams\n",
    "Produce some Venn diagrams to show hwo the different sets of papers/authors relate to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28113a84-af9a-42b7-87f8-673882e2971d",
   "metadata": {},
   "source": [
    "## Get the groups of papers, cites, and author pubs\n",
    "We distinsguis between the core RS papers (Rp), the cite of linked papers (Lp) which cite or are cited by Rp, and the author papers (Ap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df442a4-f316-4bfc-83ba-12b3236808ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_groups(recsys_papers_df):\n",
    "\n",
    "    # The set of all recsys papers.\n",
    "    Rp = set(recsys_papers_df['paperId'].unique())\n",
    "\n",
    "    # The authors of these papers.\n",
    "    recsys_author_ids = set(recsys_papers_df['authors'].explode().dropna().unique())\n",
    "    \n",
    "    # Just the citations of the recsys papers; these can/will include non-recsys papers.\n",
    "    cites = set(recsys_papers_df['updated_citations'].explode().dropna().unique())\n",
    "    refs = set(recsys_papers_df['references'].explode().dropna().unique())\n",
    "    Lp = cites.union(refs)\n",
    "\n",
    "    # The publications of the authors of these papers; these must include the recsys papers themselves and because of some\n",
    "    # minor data issues there are some that are missing, hence we union with Rp to ensure we have all of Rp in Ap.\n",
    "    Ap = set(authors_df.set_index('authorId').reindex(list(recsys_author_ids))['papers'].explode().dropna().unique()).union(Rp)\n",
    "\n",
    "    # The universe is the union of all of these papers.\n",
    "    Up = Rp.union(Lp).union(Ap)\n",
    "\n",
    "    return Up, Rp, Lp, Ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae596d9b-4fdd-4303-af87-e5462e4c4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Up, Rp, Lp, Ap = get_paper_groups(recsys_papers_df)\n",
    "len(Up), len(Rp), len(Lp), len(Ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1c8b4-dc2b-4ca2-b8e7-3221baa204d9",
   "metadata": {},
   "source": [
    "## The author groups\n",
    "A similar approach for the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726504a-6adf-4003-b331-06b620b99d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the author groups for recsys papers; note we need to pass in the larger\n",
    "# papers_df in order to to find the authors for citations and pubs that are\n",
    "# not recsys papers.\n",
    "\n",
    "def get_author_groups(papers_df, recsys_papers_df):\n",
    "\n",
    "    Up, Rp, Lp, Ap = get_paper_groups(recsys_papers_df)\n",
    "\n",
    "    papers_df_by_paper_id = papers_df.set_index('paperId')\n",
    "\n",
    "    # The authors of recsys papers.\n",
    "    # Ra = set(papers_df_by_paper_id.reindex(Rp)['authors'].explode().dropna().unique())\n",
    "    Ra = set(recsys_papers_df['authors'].explode().dropna().unique())\n",
    "\n",
    "    # The authors of citations to recsys papers\n",
    "    La = set(papers_df_by_paper_id.reindex(Lp)['authors'].explode().dropna().unique())\n",
    "\n",
    "    Aa = set(papers_df_by_paper_id.reindex(Ap)['authors'].explode().dropna().unique())\n",
    "\n",
    "    Ua = Ra.union(La).union(Aa)\n",
    "\n",
    "    return Ua, Ra, La, Aa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507ad9a-4b66-49e0-9b09-eeacca58e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ua, Ra, La, Aa = get_author_groups(papers_df, recsys_papers_df)\n",
    "len(Ua), len(Ra), len(La), len(Aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dea57a-9951-43b9-82d7-721abb9690d0",
   "metadata": {},
   "source": [
    "## Draw the Papers and Authors Venns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694b441-12cb-498e-87b9-46e00d192e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_by_id = papers_df.set_index('paperId')\n",
    "Up_df = papers_by_id.reindex(list(Up)).reset_index()\n",
    "Up_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690e56f-196d-4694-b567-f9b63bd6bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paper_ids = set(Up_df['paperId'].unique())\n",
    "all_citation_ids = set(Up_df['updated_citations'].explode().dropna().unique())\n",
    "all_reference_ids = set(Up_df['references'].explode().dropna().unique())\n",
    "all_author_pub_ids = set(authors_df['papers'].explode().dropna().unique())\n",
    "\n",
    "(\n",
    "    len(all_paper_ids), \n",
    "    len(all_citation_ids), \n",
    "    len(all_reference_ids), \n",
    "    len(all_author_pub_ids), \n",
    "    len(all_paper_ids.union(all_citation_ids).union(all_reference_ids).union(all_author_pub_ids))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d06bf7-866f-46d1-a554-7d60269ecc3d",
   "metadata": {},
   "source": [
    "The above reflects the total number of paperids that we have collected. There are 34.7M vs the 2.695M that are 1-step from a RS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db28e9-d9a1-476c-9fa8-2ec5112c7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "v1 = venn3(\n",
    "        ax=ax,\n",
    "        subsets=[Rp, Lp, Ap],\n",
    "        set_labels=['$R_p$ ({:,})'.format(len(Rp)), '$L_p$ ({:,})'.format(len(Lp)), '$A_p$ ({:,})'.format(len(Ap))],\n",
    "        set_colors=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "        subset_label_formatter=lambda v: '{:,}'.format(v),\n",
    "        alpha=.5\n",
    ") \n",
    "c1=venn3_circles(ax=ax, subsets=[Rp, Lp, Ap], linestyle='-', linewidth=1, color=\"k\")\n",
    "\n",
    "\n",
    "# Scale based on radii of the largest circle.\n",
    "# (2037307/3.1416)**.5/(2635519/3.1416)**.5\n",
    "\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the labelling for the first venn\n",
    "Rp_label = v1.get_label_by_id('A')\n",
    "ax.annotate(Rp_label.get_text(), xy=Rp_label.get_position()+np.array([-.02, -.035]), xytext=Rp_label.get_position()+np.array([-25, 35]),\n",
    "             ha='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=Rp_label.get_fontsize())\n",
    "Rp_label.set_text('')\n",
    "\n",
    "label_101 = v1.get_label_by_id('101')\n",
    "ax.annotate(label_101.get_text(), xy=label_101.get_position()+np.array([.005, 0]), xytext=label_101.get_position()+np.array([-35, 0]),\n",
    "             ha='right', va='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=label_101.get_fontsize())\n",
    "label_101.set_text('')\n",
    "\n",
    "label_111 = v1.get_label_by_id('111')\n",
    "ax.annotate(label_111.get_text(), xy=label_111.get_position()+np.array([-.04, .02]), xytext=label_111.get_position()+np.array([-40, -40]),\n",
    "             ha='center', va='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=label_111.get_fontsize())\n",
    "label_111.set_text('')\n",
    "\n",
    "label_011 = v1.get_label_by_id('011')\n",
    "label_011.set_position(label_011.get_position() + np.array([.03, -.02]))\n",
    "\n",
    "label_010 = v1.get_label_by_id('010')\n",
    "label_010.set_position(label_010.get_position() + np.array([-.05, -.04]))\n",
    "\n",
    "\n",
    "\n",
    "ax.text(\n",
    "    0, .91, \n",
    "    '$U_p$ (n = {:,})'.format(len(Up)),\n",
    "    ha='center', va='center', fontsize=Rp_label.get_fontsize()\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('../graphs/2300_papers_venn.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62acc36-e604-4c09-bf13-7d354372ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(figsize=(6, 12), nrows=2)\n",
    "\n",
    "v1 = venn3(\n",
    "        ax=ax,\n",
    "        subsets=[Rp, Lp, Ap],\n",
    "        set_labels=['$R_p$ ({:,})'.format(len(Rp)), '$L_p$ ({:,})'.format(len(Lp)), '$A_p$ ({:,})'.format(len(Ap))],\n",
    "        set_colors=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "        subset_label_formatter=lambda v: '{:,}'.format(v),\n",
    "        alpha=.5\n",
    ") \n",
    "c1=venn3_circles(ax=ax, subsets=[Rp, Lp, Ap], linestyle='-', linewidth=1, color=\"k\")\n",
    "\n",
    "\n",
    "\n",
    "v2 = venn3(\n",
    "        ax=bx,\n",
    "        subsets=[Ra, La, Aa],\n",
    "        set_labels=['$R_a$ ({:,})'.format(len(Ra)), '$L_a$ ({:,})'.format(len(La)), '$A_a$ ({:,})'.format(len(Aa))],\n",
    "        set_colors=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "        subset_label_formatter=lambda v: '{:,}'.format(v),\n",
    "        alpha=.5\n",
    ")\n",
    "c2=venn3_circles(ax=bx, subsets=[Ra, La, Aa], linestyle='-', linewidth=1, color=\"k\")\n",
    "\n",
    "\n",
    "# Scale based on radii of the largest circle.\n",
    "# (2037307/3.1416)**.5/(2635519/3.1416)**.5\n",
    "\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "bx.set_xlim(-.87, .87)\n",
    "bx.set_ylim(-.87, .87)\n",
    "\n",
    "\n",
    "\n",
    "ax.text(\n",
    "    0, .91, \n",
    "    '(a) All Papers (n = {:,})'.format(len(Rp.union(Lp).union(Ap))),\n",
    "    ha='center', va='center'\n",
    ")\n",
    "\n",
    "bx.text(\n",
    "    0, .8, \n",
    "    '(b) All Authors (n = {:,})'.format(len(Ra.union(La).union(Aa))),\n",
    "    ha='center', va='center'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the labelling for the first venn\n",
    "Rp_label = v1.get_label_by_id('A')\n",
    "ax.annotate(Rp_label.get_text(), xy=Rp_label.get_position()+np.array([-.02, -.035]), xytext=Rp_label.get_position()+np.array([-25, 35]),\n",
    "             ha='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=Rp_label.get_fontsize())\n",
    "Rp_label.set_text('')\n",
    "\n",
    "label_101 = v1.get_label_by_id('101')\n",
    "ax.annotate(label_101.get_text(), xy=label_101.get_position()+np.array([.005, 0]), xytext=label_101.get_position()+np.array([-50, 0]),\n",
    "             ha='right', va='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=label_101.get_fontsize())\n",
    "label_101.set_text('')\n",
    "\n",
    "label_111 = v1.get_label_by_id('111')\n",
    "ax.annotate(label_111.get_text(), xy=label_111.get_position()+np.array([-.04, .02]), xytext=label_111.get_position()+np.array([-40, -40]),\n",
    "             ha='center', va='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=label_111.get_fontsize())\n",
    "label_111.set_text('')\n",
    "\n",
    "label_011 = v1.get_label_by_id('011')\n",
    "label_011.set_position(label_011.get_position() + np.array([.04, 0]))\n",
    "\n",
    "label_010 = v1.get_label_by_id('010')\n",
    "label_010.set_position(label_010.get_position() + np.array([-.025, -.04]))\n",
    "\n",
    "# Adjust the labelling for the second venn\n",
    "Ra_label = v2.get_label_by_id('A')\n",
    "bx.annotate(Ra_label.get_text(), xy=Ra_label.get_position()+np.array([-.01, -.035]), xytext=Ra_label.get_position()+np.array([-25, 35]),\n",
    "             ha='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=Ra_label.get_fontsize())\n",
    "Ra_label.set_text('')\n",
    "\n",
    "label_101 = v2.get_label_by_id('101')\n",
    "bx.annotate(label_101.get_text(), xy=label_101.get_position()+np.array([.01, 0]), xytext=label_101.get_position()+np.array([-25, 0]),\n",
    "             ha='right', va='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=label_101.get_fontsize())\n",
    "label_101.set_text('')\n",
    "\n",
    "label_111 = v2.get_label_by_id('111')\n",
    "bx.annotate(label_111.get_text(), xy=label_111.get_position()+np.array([-.04, .02]), xytext=label_111.get_position()+np.array([-40, -40]),\n",
    "             ha='center', va='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=label_111.get_fontsize())\n",
    "label_111.set_text('')\n",
    "\n",
    "# label_011 = v2.get_label_by_id('011')\n",
    "# label_011.set_position(label_011.get_position() + np.array([.03, 0]))\n",
    "\n",
    "label_010 = v2.get_label_by_id('010')\n",
    "label_010.set_position(label_010.get_position() + np.array([-.025, -.04]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.text(\n",
    "    0, .91, \n",
    "    '(a) All Papers (n = {:,})'.format(len(Rp.union(Lp).union(Ap))),\n",
    "    ha='center', va='center', fontsize=label_111.get_fontsize()\n",
    ")\n",
    "\n",
    "bx.text(\n",
    "    0, .8, \n",
    "    '(b) All Authors (n = {:,})'.format(len(Ra.union(La).union(Aa))),\n",
    "    ha='center', va='center', fontsize=label_111.get_fontsize()\n",
    ")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('../graphs/2300_papers_authors_venn.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1bb53b-282a-4d6f-96cc-45a1fb3b8f69",
   "metadata": {},
   "source": [
    "# Inside & Outside Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538d188-6dc7-4afc-9c80-907f318fa52c",
   "metadata": {},
   "source": [
    "## The Core/Venue Papers\n",
    "These are the papers that have been published at RecSys or one of its associated venues (workshops, TORS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42896b1-05d6-4f3e-be84-c02d8d069738",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_papers_df = recsys_papers_df[recsys_papers_df['is_venue_paper']]\n",
    "venue_paper_ids = set(venue_papers_df['paperId'].unique())\n",
    "\n",
    "venue_papers_df.shape, len(venue_paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0e0c1-9a57-41d8-9ed8-25c05b19546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_author_ids = set(venue_papers_df['authors'].explode().dropna().unique())\n",
    "len(venue_author_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a0ed3-d62a-4fba-8a77-e58628945573",
   "metadata": {},
   "source": [
    "## Identifying Inside/Outside Papers/Authors\n",
    "This is where we define the inside and outside communities based on publication related to the main/core RS venues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbbeba-67e7-4f21-9188-77ae38502c3c",
   "metadata": {},
   "source": [
    "### Inside Papers & Authors\n",
    "An inside paper is a recsys paper with an author who has published in the core venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37961e52-cd68-48a3-9786-d73fc3089cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the papers published by core authors/recsys venue authors.\n",
    "has_venue_author = (\n",
    "    papers_df['authors']\n",
    "    .swifter\n",
    "    .apply(lambda authors: len(set(authors).intersection(venue_author_ids))>0)\n",
    ")\n",
    "\n",
    "has_venue_author.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c611e74-130a-4f38-aedd-66413e180f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An inside paper is a recsys paper with a recsys author or co-author.\n",
    "is_inside_paper = is_recsys_paper & has_venue_author\n",
    "\n",
    "inside_papers = papers_df[is_inside_paper]\n",
    "\n",
    "inside_paper_ids = set(inside_papers['paperId'].unique())\n",
    "\n",
    "len(inside_paper_ids), inside_papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191e1a4-570c-4978-a89a-0160876dca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inside authors are all those who have authored inside papers.\n",
    "inside_author_ids = set(inside_papers['authors'].explode().dropna().unique())\n",
    "\n",
    "len(inside_author_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3c857-53b9-42e3-b71c-2af083c5063e",
   "metadata": {},
   "source": [
    "### Outside Papers & Authors\n",
    "Similarly we need to define the otside papers/authors. An outside paper is a RS paper that is not an inside paper. An outside author is an author of an outside paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4a9ea-5cd8-494d-82f5-84c61deae109",
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_papers = papers_df[is_recsys_paper & (~is_inside_paper)]\n",
    "\n",
    "outside_paper_ids = set(outside_papers['paperId'].unique())\n",
    "\n",
    "len(outside_paper_ids), outside_papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20ff3c-7472-4f70-9144-a61a59f66128",
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_author_ids = set(outside_papers['authors'].explode().dropna().unique())\n",
    "\n",
    "len(outside_author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c17b0-8925-4613-90aa-be366f5ca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_paper_ids.intersection(inside_paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8defd756-0460-467c-9d11-450822a8ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outside_author_ids.intersection(inside_author_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c419f-9c5e-4f36-a0d0-160a4a73a719",
   "metadata": {},
   "source": [
    "### Mark papers/authors with inside/outside indicator\n",
    "We need to be careful with the ordering here -- there might be a better way to do this ... -- so that the papers that are both inside and outside are considered to be inside, as this is what is intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010d276-e27b-492d-a4e2-85d294c5606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_papers_df['paper_type'] = np.where(recsys_papers_df['paperId'].isin(outside_paper_ids), 'outside', None)\n",
    "recsys_papers_df['paper_type'] = np.where(recsys_papers_df['paperId'].isin(inside_paper_ids), 'inside', recsys_papers_df['paper_type'])\n",
    "\n",
    "recsys_papers_df['paper_type'].unique(), recsys_papers_df.groupby('paper_type').size(), recsys_papers_df.groupby('paper_type').size().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f8540-c98f-4ac4-89da-b8dc7ab48028",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outside_author = authors_df['authorId'].isin(outside_author_ids)\n",
    "is_inside_author = authors_df['authorId'].isin(inside_author_ids)\n",
    "\n",
    "authors_df.loc[is_outside_author, 'author_type'] = 'outside'\n",
    "authors_df.loc[is_inside_author, 'author_type'] = 'inside'\n",
    "authors_df.loc[(~is_outside_author) & (~is_inside_author), 'author_type'] = 'non-inside_outside'\n",
    "\n",
    "\n",
    "# authors_df['author_type'] = np.where(authors_df['authorId'].isin(outside_author_ids), 'outside', None)\n",
    "# authors_df['author_type'] = np.where(authors_df['authorId'].isin(inside_author_ids), 'inside', authors_df['author_type'])\n",
    "\n",
    "# # If an author is neither inside nor outside then its a non-recsys author, presumably it cites of refs a recsys paper.\n",
    "# authors_df['author_type'] = np.where(authors_df['author_type'].isnull(), 'non_recsys', authors_df['author_type'])\n",
    "\n",
    "authors_df.shape, authors_df['author_type'].unique(), authors_df.groupby('author_type').size(), authors_df.groupby('author_type').size().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffc5d1-3368-44ad-a2bd-4486b94e4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also add author type to the papers DF\n",
    "has_inside_author = papers_df['authors'].swifter.apply(lambda authors: len(set(authors).intersection(inside_author_ids))>0)\n",
    "has_outside_author = papers_df['authors'].swifter.apply(lambda authors: len(set(authors).intersection(outside_author_ids))>0)\n",
    "\n",
    "papers_df.loc[has_outside_author, 'author_type'] = 'outside'\n",
    "papers_df.loc[has_inside_author, 'author_type'] = 'inside'\n",
    "papers_df.loc[(~has_outside_author) & (~has_inside_author), 'author_type'] = 'non-inside_outside'\n",
    "\n",
    "\n",
    "# papers_df['author_type'] = np.where(has_outside_author, 'outside', None)\n",
    "# papers_df['author_type'] = np.where(has_inside_author, 'inside', papers_df['author_type'])\n",
    "\n",
    "papers_df['author_type'].unique(), papers_df.groupby('author_type').size(), papers_df.groupby('author_type').size().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb55f14-e4cf-4225-ad12-7860214051bd",
   "metadata": {},
   "source": [
    "## Fix some issues noticed along the way\n",
    "A few manual fixes that are appropriate for a very small number of issues that have been noted during the analysis. Mostly these are due to some dodgy SS data records. FOrtunately, there are very few examples, at least that I have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575fee17-fdce-4384-9d93-bb9e34203658",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_papers_df.loc[1833975, 'paper_type'] = 'inside'   # F. Ricci vs Francesco Ricci\n",
    "\n",
    "recsys_papers_df.at[14164, 'venue'] = 'Computer Supported Collaborative Work'\n",
    "recsys_papers_df.at[14164, 'clean_venue'] = 'cscw'\n",
    "recsys_papers_df.at[14164, 'title'] = 'GroupLens: An open architecture for collaborative filtering of netnews'\n",
    "\n",
    "recsys_papers_df.at[14164, 'author_names'] = ['Paul Resnick', 'Neophytos Iacovou', 'Mitesh Suchak', 'Peter Bergstrom', 'John Riedl']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7325554-ceb5-44ac-a9ac-94c0b33f17d5",
   "metadata": {},
   "source": [
    "## The Inside/Outside Venn Diagrams\n",
    "Produce the Venn diagrams to show the relationships between the Inside and Outside sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d080e38-3baa-4d83-8fde-711b79d4d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(figsize=(7, 14), nrows=2)\n",
    "\n",
    "v1 = venn3(\n",
    "    ax=ax,\n",
    "    subsets=[venue_paper_ids, inside_paper_ids, outside_paper_ids],\n",
    "    set_labels=['$Vp$ ({:,})'.format(len(venue_paper_ids)), '$I_p$ ({:,})'.format(len(inside_paper_ids)), '$O_p$ ({:,})'.format(len(outside_paper_ids))],\n",
    "    set_colors=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "    subset_label_formatter=lambda v: '{:,}'.format(v),\n",
    "    alpha=.5\n",
    "      \n",
    ")\n",
    "c1=venn3_circles(ax=ax, subsets=[venue_paper_ids, inside_paper_ids, outside_paper_ids], linestyle='-', linewidth=1, color=\"k\")\n",
    "\n",
    "\n",
    "\n",
    "v2 = venn3(\n",
    "    ax=bx,\n",
    "    subsets=[venue_author_ids, inside_author_ids, outside_author_ids],\n",
    "    set_labels=['$Va$ ({:,})'.format(len(venue_author_ids)), '$I_a$ ({:,})'.format(len(inside_author_ids)), '$O_a$ ({:,})'.format(len(outside_author_ids))],\n",
    "    set_colors=['tab:blue', 'tab:orange', 'tab:green'],\n",
    "    subset_label_formatter=lambda v: '{:,}'.format(v),\n",
    "    alpha=.5\n",
    "      \n",
    ")\n",
    "c2=venn3_circles(ax=bx, subsets=[venue_author_ids, inside_author_ids, outside_author_ids], linestyle='-', linewidth=1, color=\"k\")\n",
    "\n",
    "\n",
    "\n",
    "# A bit of scaling to improve the correctness of the areas across the pair of venn.\n",
    "# (31265/3.1416)**.5/(62426/3.1416)**.5 = 0.7\n",
    "# 1/.7 = 1.42\n",
    "\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "bx.set_xlim(-.8, .8)\n",
    "bx.set_ylim(-.8, .8)\n",
    "\n",
    "\n",
    "# Adjust the labelling for the first venn\n",
    "Cp_label = v1.get_label_by_id('A')\n",
    "ax.annotate('$V_p$', xy=Cp_label.get_position()+np.array([-0.05, .17]), xytext=Cp_label.get_position()+np.array([-25, 60]),\n",
    "             ha='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=Cp_label.get_fontsize())\n",
    "Cp_label.set_text('')\n",
    "\n",
    "# Adjust the labelling for the second venn\n",
    "Ca_label = v2.get_label_by_id('A')\n",
    "bx.annotate('$V_a$', xy=Ca_label.get_position()+np.array([0, .18]), xytext=Ca_label.get_position()+np.array([10, 60]),\n",
    "             ha='center', xycoords='data', textcoords='offset points',\n",
    "             arrowprops=dict(arrowstyle='->',color='k'), fontsize=Cp_label.get_fontsize())\n",
    "\n",
    "# Ca_label.set_position(Ca_label.get_position() + np.array([0, .2]))\n",
    "Ca_label.set_text('')\n",
    "\n",
    "# label_110 = v2.get_label_by_id('110')\n",
    "# label_110.set_text('')\n",
    "\n",
    "label_010 = v2.get_label_by_id('010')\n",
    "label_010.set_position(label_010.get_position() + np.array([-0.05, -.19]))\n",
    "\n",
    "\n",
    "\n",
    "ax.text(\n",
    "    0, 1, \n",
    "    '(a) Inside & Outside Recsys Papers (n = {:,})'.format(len(inside_paper_ids.union(outside_paper_ids))),\n",
    "    ha='center', va='center', fontsize=Cp_label.get_fontsize()\n",
    ")\n",
    "\n",
    "bx.text(\n",
    "    0, .8, \n",
    "    '(b) Inside & Outside Recsys Authors (n = {:,})'.format(len(inside_author_ids.union(outside_author_ids))),\n",
    "    ha='center', va='center', fontsize=Cp_label.get_fontsize()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('../graphs/2300_inside_outside_venn.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ef0b0-71d8-403a-ab26-532ab905cbc4",
   "metadata": {},
   "source": [
    "An inside paper is either a paper that is published in one of the core venues or its a paper published by someone who has published in the core venyes; in other words, inside papers are papers that have an authorship connection to the core venues. Then, inside authors are all of the authors of inside papers. Note that some inside authors will not have published in the core venues but they may have co-authored with someone who has.\n",
    "\n",
    "This subset of the inside authors provides an important bridget to the outside papers/authors. By definition, an outside paper is a recsys paper that is not an inside paper and an outside author is an author of an outside paper. Most of these outside authors are entirely separate from the inside community. They have no published a core venue paper  nor have they co-authored any papers with an author that has published a core venue paper.\n",
    "\n",
    "Abive we see that 60k authors of recsys papers have no connection to the core recsys community, which is 4x the noumber of inside authors. Moreover, these outside authors have published more than 3x then number of recsys papers as the inside community.\n",
    "\n",
    "The significance of this is that it points to a vibrant community of recsys researchers that exists beyond the core venues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c7972-40ee-4ea3-9cba-ecaba097981a",
   "metadata": {},
   "source": [
    "# Save papers with inside/outside indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0af380-12c8-49a4-8350-ecaec991a6d0",
   "metadata": {},
   "source": [
    "## The main inside/outside dataset of RS papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d087d6-b029-49a2-b82e-31cf8b25fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_papers_df.to_feather('../data/processed/2300_inside_outside_papers.feather')\n",
    "recsys_papers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa695c5-7b84-4d31-9e54-7703edf8ea75",
   "metadata": {},
   "source": [
    "## The main RS universe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21001b1-265c-4253-98e4-9d93299b5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_universe_papers_df = papers_df[papers_df['paperId'].isin(Up)].copy()\n",
    "recsys_universe_papers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f775dda-9eb9-43ca-8dd8-99c25c62fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_universe_papers_df.to_feather('../data/processed/2300_recsys_universe_papers.feather')\n",
    "recsys_universe_papers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ac6a8-13da-4fc2-9494-962af926e2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T16:26:24.594076Z",
     "iopub.status.busy": "2024-08-06T16:26:24.593835Z",
     "iopub.status.idle": "2024-08-06T16:26:36.434077Z",
     "shell.execute_reply": "2024-08-06T16:26:36.433027Z",
     "shell.execute_reply.started": "2024-08-06T16:26:24.594056Z"
    }
   },
   "source": [
    "## The inside/outside authors dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a61d6-6a4c-4758-9bfd-036a77e411ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df.to_feather('../data/processed/2300_inside_outside_authors.feather')\n",
    "authors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8584d93-8af9-4256-87e8-ff6b7da85f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264a91b-4d2b-4fc6-bc60-e0ce6cb1d5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e19260-bbd9-4d0f-95ae-e3ca42fe9e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
