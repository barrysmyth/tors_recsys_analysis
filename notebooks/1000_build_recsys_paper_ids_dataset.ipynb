{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dc9f91-31d3-4c82-a708-28339e45b7b3",
   "metadata": {},
   "source": [
    "# Generating a reliable set of RecSys Paper Ids\n",
    "The main focus of this notebook is to generate a list of semantic scholar paper ids for recommender systems papers. We are not interested in getting the paper records themselves, this will be the job of the next notebook, but rather the ids that can be used later to lookup the paper records on SS.\n",
    "\n",
    "To do this we will use two metods:\n",
    "1. Using  conference and journal paper data colleected from DBLP we can identify DLBP papers that are recsys related. We can do this by identifying papers from recommender system venues (RecSys for example).\n",
    "2. We can search DBLP titles and venues for recommender systems like phrases.\n",
    "\n",
    "Once we have a suitable set of DBLP papers then we can identify those that have DOIs and use thes to collect paper ids from SS.\n",
    "\n",
    "Note: This notbeook does not need to be executed. The file, '../data/raw/1000_recsys_paper_ids_52550.feather' contains the paper ids that are produced from this notebook at the time of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169050f-d22d-47bc-943e-4272c6775af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import swifter\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import string \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import requests\n",
    "from itertools import chain\n",
    "from more_itertools import sliced\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.pylab import plt\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "\n",
    "from loguru import logger\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "from semantic_scholar_wrapper import SS\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd682f-2482-4d5f-8365-1a96686fdf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SS()\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23575f1-27b0-4194-8ff6-4e49df107988",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f4813-650c-4d04-966b-64d835232a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook will produce a dataset of paper ids that will be stored in this file.\n",
    "recsys_paper_ids_dataset = '../data/raw/1000_recsys_paper_ids.feather'\n",
    "\n",
    "# It will use a previously collected dataset of DBLP journal and conference papers as seeds for this.\n",
    "dblp_journals_dataset = '../data/raw/dblp_journals_with_ss_paper_ids.feather'\n",
    "dblp_conferences_dataset = '../data/raw/dblp_conferences_with_ss_paper_ids.feather'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253d5f1-2e85-406f-a11e-492d3fbef41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SS fields used when collecting paper and author records.\n",
    "\n",
    "paper_fields = [\n",
    "        'paperId', 'title', 'url', 'venue', 'year', 'journal', 'isOpenAccess',\n",
    "        'publicationTypes', 'publicationDate',\n",
    "        'referenceCount', 'citationCount', 'influentialCitationCount', \n",
    "        'fieldsOfStudy',\n",
    "        'abstract',    \n",
    "        'authors.authorId', 'citations.paperId',  'references.paperId',\n",
    "        'externalIds'\n",
    "    ]\n",
    "\n",
    "author_fields = [\n",
    "    'authorId' ,'externalIds' ,'name' ,'affiliations'\n",
    "    ,'paperCount' ,'citationCount' ,'hIndex' ,'papers.paperId'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64592f72-d48c-4934-9d24-07413a591e34",
   "metadata": {},
   "source": [
    "# Find RecSys Papers in DBLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc6017-84a5-489b-9501-c2a52ebe7a97",
   "metadata": {},
   "source": [
    "Read in and combine the DBLP datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2234e4a-df83-46c4-83fa-83c68e35f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_journals_df = pd.read_feather(dblp_journals_dataset)\n",
    "dblp_journals_df.shape, dblp_journals_df['ss_paperId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68e0ba-dd70-465b-a614-c86426455feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_conferences_df = pd.read_feather(dblp_conferences_dataset)\n",
    "dblp_conferences_df.shape, dblp_conferences_df['ss_paperId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7be3e-9bbd-4599-a266-2d5909edcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df = pd.concat([dblp_journals_df, dblp_conferences_df], ignore_index=True)\n",
    "\n",
    "dblp_df.shape, dblp_df['ss_paperId'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a9694-9767-47c9-a045-64e9592f19ae",
   "metadata": {},
   "source": [
    "We only need to focus on the unique paper ids, so drop duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae355c47-6c2a-41e8-8863-aea9be21e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df = dblp_df[dblp_df['ss_paperId'].notnull()].drop_duplicates(subset=['ss_paperId']).copy()\n",
    "dblp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4a786-8c32-4267-897a-4c31b9346004",
   "metadata": {},
   "source": [
    "Combine these text columns together into a single string and remove punctuation. This will be useful to do some lookup of key recsys terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b083cb-5785-44ad-86f5-5ba445b37465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_cols = [\n",
    "    'dblp_title', \n",
    "    'dblp_journal_name', 'dblp_booktitle', \n",
    "    'dblp_conference_name', 'dblp_proceedings_publisher',\n",
    "]\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "\n",
    "    # Add the single quote and drop the hyphen\n",
    "    punctuation = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~' + \"â€™\"\n",
    "\n",
    "    # Create a translation table mapping punctuation characters to None\n",
    "    translator = str.maketrans('', '', punctuation)\n",
    "    \n",
    "    # Remove punctuation using translate method\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "dblp_df['text'] = (\n",
    "    dblp_df[text_cols]\n",
    "    .swifter\n",
    "    .apply(lambda row: remove_punctuation(' '.join(row.dropna().map(str)).lower()), axis=1)\n",
    ")\n",
    "\n",
    "dblp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76fc8b9-3508-4cdc-bb35-1c0abbf9d52c",
   "metadata": {},
   "source": [
    "## RecSys DBLP Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b712e4-56da-4e81-a1ce-644862e82623",
   "metadata": {},
   "source": [
    "Let's identify the DBLP keys that are associated with the main RecSys venues. These incldue ACM RecSys, ToRS and several long-running workshop series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c3f63-4cb4-42e6-b629-0f2e53d4a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_keys = [\n",
    "    'recsys', 'conf/hr-recsys', 'conf/orsum', 'conf/normalize', 'conf/behavrec', 'conf/inra', 'conf/intrs',\n",
    "    'conf/kars', 'conf/leri', 'conf/rectour',  \n",
    "    'journals/tors', \n",
    "]\n",
    "\n",
    "def contains_phrases(text, phrases):\n",
    "    for phrase in phrases:\n",
    "        if phrase in text: return True\n",
    "\n",
    "    return False\n",
    "\n",
    "with_recsys_key = dblp_df['dblp_key'].map(lambda text: contains_phrases(text, recsys_keys))\n",
    "with_recsys_key.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5abdd-881e-4469-9cc2-eb1a4706220d",
   "metadata": {},
   "source": [
    "## RecSys Phrases & Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971778d-e2a6-47bc-befc-8d508b23e299",
   "metadata": {},
   "source": [
    "Next we define key RecSys phrases to identify papers that contain these phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dfa63-bd9d-4204-93e4-dfaaff3bb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the queries we will use for SS search; note the quotations for exact match search.\n",
    "recsys_queries = [\n",
    "    '\"recommender system\"', '\"recommendation system\"', \n",
    "    '\"collaborative filter\"', '\"collaborative recommend\"',\n",
    "    '\"social information filter\"', '\"collaborative information filter\"',\n",
    "    '\"user-item\"',\n",
    "    'recsys', 'grouplens', 'movielens', '\"netflix prize\"',\n",
    "]\n",
    "\n",
    "# To check DBLP titles we dont need the quotes and we will add 'recommender'\n",
    "recsys_phrases = [q.replace('\"', '') for q in recsys_queries] + ['recommender']\n",
    "\n",
    "with_recsys_phrase = dblp_df['text'].swifter.apply(lambda text: contains_phrases(text, phrases=recsys_phrases))\n",
    "\n",
    "with_recsys_phrase.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed340a7-dc01-4a20-abde-92f63b48ab09",
   "metadata": {},
   "source": [
    "## Combine RecSys Papers from DBLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f651c-f394-4ac6-a504-974748313d62",
   "metadata": {},
   "source": [
    "Focus on any papers that come from one of the main RecSys venues or contain a RecSys phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6dd46-d855-448b-8a8c-a732c20a69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_dblp_paper_df = dblp_df[(with_recsys_key | with_recsys_phrase)]\n",
    "recsys_dblp_paper_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc545f88-f946-4701-8bfc-f18830090a8e",
   "metadata": {},
   "source": [
    "Get the unique paper ids; these are the ids that Semantic Scholar uses for its API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd365c1f-6039-453a-aadc-f96215c0906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_dblp_paper_ids = list(recsys_dblp_paper_df['ss_paperId'].unique())\n",
    "len(recsys_dblp_paper_ids), recsys_dblp_paper_ids[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8319878-2a9f-4797-bb93-d3b4870994d1",
   "metadata": {},
   "source": [
    "# RecSys Papers on SS\n",
    "Next, search Semantic Scholar using the RecSys queries/phrases defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d16e1-0dc7-4542-90d7-4e5b9e058bf0",
   "metadata": {},
   "source": [
    "## Search SS using RecSys queries and combine results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab09680-9084-4fbe-9ee5-481696a7cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_fields = ['title', 'abstract', 'venue', 'year']\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for recsys_query in recsys_queries:\n",
    "    clear_output()\n",
    "    logger.info(recsys_query)\n",
    "    search_results.append(ss.bulk_paper_search(recsys_query, fields=search_fields, sleep=1))\n",
    "\n",
    "search_results = list(chain.from_iterable(search_results))\n",
    "\n",
    "len(search_results), search_results[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbfa49-b3d3-49fe-a8e9-66f4e7a6f0c1",
   "metadata": {},
   "source": [
    "Combine the search results into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efea4d-cb4b-4fda-b257-3a63170edcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results_df = pd.DataFrame(search_results)\n",
    "\n",
    "# Combine the title, abstract, venue into a text column.\n",
    "search_results_df['text'] = (search_results_df['title'].map(str) + search_results_df['abstract'].map(str) + search_results_df['venue'].map(str)).map(remove_punctuation)\n",
    "\n",
    "search_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347f9b9-2fc2-4869-83f2-0e08dffa2d64",
   "metadata": {},
   "source": [
    "## Validate the Search Results\n",
    "Check to see if the `text` column does contain a recsys query; if it does its considered a valud search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fa725-677c-4684-9b78-d8280f8695fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results_df['is_valid'] = search_results_df['text'].map(\n",
    "    lambda text: contains_phrases(text, [q.replace('\"', '') for q in recsys_queries])\n",
    ")\n",
    "\n",
    "search_results_df['is_valid'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbba54-01d1-4c37-aa87-93c7ce86c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_search_results_df = search_results_df[search_results_df['is_valid']]\n",
    "valid_search_results_df.shape, valid_search_results_df['title'].sample(20).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092ba8d-5ffa-4fc3-9115-bf516a0b268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_valid_search_paper_ids = list(valid_search_results_df['paperId'].unique())\n",
    "len(recsys_valid_search_paper_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fae7ed-3360-4ec2-ac65-0c5d26f45036",
   "metadata": {},
   "source": [
    "# Prepare the Dataset of Initial RecSys IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9fce9-e3f4-4a84-9e23-0407a1a25662",
   "metadata": {},
   "source": [
    "## Combine DBLP and SS RecSys Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402064c-f72d-476c-a780-fb5097aa8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_paper_ids_df = pd.DataFrame(list(set(recsys_dblp_paper_ids).union(recsys_valid_search_paper_ids)), columns=['paperId'])\n",
    "recsys_paper_ids_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf3801-1fa8-42ba-8c5f-db7994d8c965",
   "metadata": {},
   "source": [
    "## Save RecSys Paper Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33cc1f-a014-4e04-b9b3-fd096b8ff35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_paper_ids_df.to_feather(recsys_paper_ids_dataset)\n",
    "\n",
    "recsys_paper_ids_dataset.format(len(recsys_paper_ids_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cea02-75cc-425b-8295-1bd43b674252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
