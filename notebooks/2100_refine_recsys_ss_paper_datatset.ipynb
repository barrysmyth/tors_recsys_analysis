{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a26025-149c-49e5-b4ae-2cc3a34f48f5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "At this stage we have a dataset of recsys papers which contains a subset of papers that are about recommender systems plus a larger set of linked papers that are either cites, refs or author publications. The core recommender systems papers are not perfect. At least some are accidental remindings and the purpose of this notebook is to try to refine this in order to focus in on a optimal core of on-point recomender systems papers.\n",
    "\n",
    "We will not remove any papers from this dataset but rather try to make them as recsys-relevant or not. The approach taken will be to be conservative: to only consider papers as being core RS papers if there is a strong reason to do so. In particular, we will try to excldue papers that mention RS in passing, perhaps as an application area or as related work, wut without evidence of a material contribution to the RS field. This is a question of balance and one culd argue that the approach taken here is too conservative. That is a useful debate to have and it will be possible for others to adjust the refinement process here in order to loosen the constraints. However, it should be noted that by allowing more borderline papers to be considered as core RS papers, it will also likley increase the number of much less relevant papers too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169050f-d22d-47bc-943e-4272c6775af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import random\n",
    "from itertools import chain\n",
    "from more_itertools import sliced\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.pylab import plt\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "\n",
    "from loguru import logger\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72994bc0-9dae-483a-9f91-4ce8fdb6b9b9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4729749a-27d0-4b37-bc8a-5de98d36551a",
   "metadata": {},
   "source": [
    "## Datasets and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd640f0b-92ea-46e6-bfd6-5d700c539aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main dataset of papers, which includes a subset of RS papers.\n",
    "recsys_papers_dataset = '../data/raw/2000_recsys_papers.feather'\n",
    "\n",
    "# We will save this refined dataset in the `processed` data subdirectory; it is no longer strictly raw data.\n",
    "refined_recsys_papers_dataset = recsys_papers_dataset.replace('raw/2000_recsys', 'processed/2100_refined_recsys')\n",
    "refined_recsys_papers_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302253b9-c5ac-4b9c-9ad7-9873acbb5add",
   "metadata": {},
   "source": [
    "## Load the main papers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77397c1-96c1-4fd9-a135-d2d1439d90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(recsys_papers_dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011291b6-b50c-47bb-a961-876b789949ca",
   "metadata": {},
   "source": [
    "## The curent subset of RS papers\n",
    "These are the papers that have been so far deemed to be RS papers, within the larger collection of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ab7eb-3fc8-479e-904e-45194cb3cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_df = df[df['is_recsys_paper']].copy()\n",
    "recsys_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159c0b1-bcd6-4517-b349-1041b53d854a",
   "metadata": {},
   "source": [
    "# RecSys Filters\n",
    "Various filters that we will use to determine whether a paper should be considered as a true/core RecSys paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6f0d6-a080-4c2f-905a-4e1036529d3a",
   "metadata": {},
   "source": [
    "## Does the paper contain a recsys dblp key?\n",
    "Any paper/record that uses one of the predefined RecSys (DBLP) keys (e.g. ACM RecSys, ToRs, various RecSys Workshops) will be consisdered to be a core RS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10985ab9-bc0e-4f08-8df1-5de19e6538e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_dblp_key = df['DBLP'].notnull()\n",
    "\n",
    "recsys_keys = [\n",
    "    'recsys', 'conf/hr-recsys', 'conf/orsum', 'conf/normalize', 'conf/behavrec', 'conf/inra', 'conf/intrs',\n",
    "    'conf/kars', 'conf/leri', 'conf/rectour',  \n",
    "    'journals/tors', \n",
    "]\n",
    "\n",
    "df.loc[with_dblp_key, 'has_recsys_key'] = df[with_dblp_key]['DBLP'].swifter.apply(\n",
    "    lambda dblp_key: len([key for key in recsys_keys if key in dblp_key])>0)\n",
    "\n",
    "df['has_recsys_key'] = df['has_recsys_key'].fillna(False)\n",
    "\n",
    "df['has_recsys_key'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28707d1a-3468-451d-8c0b-d6c9c1df58f1",
   "metadata": {},
   "source": [
    "## Is the paper a candidate recsys paper?\n",
    "We are starting to distibguish between candidate RS papers and true/core RS papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f2ced-d213-43be-bafd-60a60b3131d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_candidate_recsys_paper'] = df['is_recsys_paper']\n",
    "df['is_candidate_recsys_paper'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c6140-85ea-4236-bbcc-b09e58757513",
   "metadata": {},
   "source": [
    "## Is the paper in the correct time frame?\n",
    "In this work we focus on 1990 - 2024. The 1990 year is somewhat abritrary but it does suffice as a sensible starting point for RS work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6efefc-80f5-4a1b-b673-6ada30f3a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_recsys_years = df['year'].between(1990, 2024)\n",
    "\n",
    "df['is_within_recsys_years'] = within_recsys_years\n",
    "\n",
    "df['is_within_recsys_years'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f2796-be20-4655-b636-1c210b9e6a9f",
   "metadata": {},
   "source": [
    "## Does the paper contain any strong recsys phrases?\n",
    "These are phrases that are strongly indicative of core RS work. They need to appear as exact matches in a paper record. Here we look for these phrases in the sbgrast, title, and venue texts and calculate various counts of their occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636904b-9e43-486e-a3bf-d896e8671147",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_recsys_phrases = [\n",
    "    'recommender', \n",
    "    'collaborative filter', 'social information filter', 'collaborative information filter', 'social information access',\n",
    "    'recsys', 'movielens', 'grouplens', 'netflix prize'\n",
    "]\n",
    "\n",
    "def check_phrases(text, phrases=strong_recsys_phrases):\n",
    "    return [phrase for phrase in phrases if phrase in text.lower()]\n",
    "\n",
    "df['contains_strong_recsys_phrases'] = df['text'].swifter.apply(check_phrases)\n",
    "df['num_strong_recsys_phrases'] = df['contains_strong_recsys_phrases'].map(len)\n",
    "\n",
    "df['contains_strong_recsys_phrases_in_title'] = df['title'].swifter.apply(check_phrases)\n",
    "df['num_strong_recsys_phrases_in_title'] = df['contains_strong_recsys_phrases_in_title'].map(len)\n",
    "\n",
    "df['contains_strong_recsys_phrases_in_venue'] = df['venue'].swifter.apply(check_phrases)\n",
    "df['num_strong_recsys_phrases_in_venue'] = df['contains_strong_recsys_phrases_in_venue'].map(len)\n",
    "\n",
    "(df['num_strong_recsys_phrases']>0).sum(), (df['num_strong_recsys_phrases_in_title']>0).sum(), (df['num_strong_recsys_phrases_in_venue']>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af8782-2be8-4ba5-89ed-e6a5fbdc8706",
   "metadata": {},
   "source": [
    "## Does it contain moderate recsys phrases\n",
    "Similar to above but focusing on a weaker set of phrases; after some experimentation this set of moderate phrases turned out to me minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca081f6-4281-4933-a5ef-18016c5cf8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_recsys_phrases = [\n",
    "    'recommendation system',\n",
    "]\n",
    "\n",
    "df['contains_moderate_recsys_phrases'] = df['text'].swifter.apply(lambda text: check_phrases(text, moderate_recsys_phrases))\n",
    "df['num_moderate_recsys_phrases'] = df['contains_moderate_recsys_phrases'].map(len)\n",
    "\n",
    "df['contains_moderate_recsys_phrases_in_title'] = df['title'].swifter.apply(lambda text: check_phrases(text, moderate_recsys_phrases))\n",
    "df['num_moderate_recsys_phrases_in_title'] = df['contains_moderate_recsys_phrases_in_title'].map(len)\n",
    "\n",
    "df['contains_moderate_recsys_phrases_in_venue'] = df['venue'].swifter.apply(lambda text: check_phrases(text, moderate_recsys_phrases))\n",
    "df['num_moderate_recsys_phrases_in_venue'] = df['contains_moderate_recsys_phrases_in_venue'].map(len)\n",
    "\n",
    "(df['num_moderate_recsys_phrases']>0).sum(), (df['num_moderate_recsys_phrases_in_title']>0).sum(), (df['num_moderate_recsys_phrases_in_venue']>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c80cf-610b-4de0-bf58-8e55b491404e",
   "metadata": {},
   "source": [
    "## Does it contain any weak recsys phrases?\n",
    "And finally the weakest phrases indicative of recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a060b-6f7b-4298-993b-7c5dd0b38453",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_recsys_phrases = ['recommendation']\n",
    "\n",
    "df['contains_weak_recsys_phrases'] = df['text'].swifter.apply(lambda text: check_phrases(text, weak_recsys_phrases))\n",
    "df['num_weak_recsys_phrases'] = df['contains_weak_recsys_phrases'].map(len)\n",
    "\n",
    "(df['num_weak_recsys_phrases']>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0bfd7-dd0b-4442-9e7a-923d49c73fa1",
   "metadata": {},
   "source": [
    "## What is the max candidate recsys authorship count for the paper?\n",
    "That is, how many candidate recsys papers has each author produced? What its the max for the paper? This is a useful feature to consider when looking at some weaker examples of RS work. If there is an author who has published plenty of core RS papers then perhaps a weaker RS paper by that author is safer to consider as a core RS paper than a similar paper from an author with little or no RS history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87006cf-416e-4436-9c3d-b56cf354427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_df = df[df['is_candidate_recsys_paper']].copy()\n",
    "\n",
    "# A mapping between papers ids and author ids\n",
    "authors_by_paper = df.set_index('paperId')['authors'].explode().dropna().reset_index()\n",
    "recsys_authors_by_paper = recsys_df.set_index('paperId')['authors'].explode().dropna().reset_index()\n",
    "\n",
    "# The number of papers for each author id\n",
    "num_papers_by_author = authors_by_paper.groupby('authors').size()\n",
    "num_recsys_papers_by_author = recsys_authors_by_paper.groupby('authors').size()\n",
    "\n",
    "# The authorship counts\n",
    "df['authorship_counts'] = (\n",
    "    df['authors']\n",
    "    .swifter\n",
    "    .apply(\n",
    "        lambda authors: [\n",
    "            num_papers_by_author.loc[author] \n",
    "            for author in authors \n",
    "            if author in num_papers_by_author.index\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "df['recsys_authorship_counts'] = (\n",
    "    df['authors']\n",
    "    .swifter\n",
    "    .apply(\n",
    "        lambda authors: [\n",
    "            num_recsys_papers_by_author.loc[author] \n",
    "            for author in authors \n",
    "            if author in num_recsys_papers_by_author.index\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "df['min_authorship_count'] = (\n",
    "    df['authorship_counts']\n",
    "    .swifter\n",
    "    .apply(lambda counts: min(counts) if len(counts)>0 else 0)\n",
    ")\n",
    "\n",
    "df['min_recsys_authorship_count'] = (\n",
    "    df['recsys_authorship_counts']\n",
    "    .swifter\n",
    "    .apply(lambda counts: min(counts) if len(counts)>0 else 0)\n",
    ")\n",
    "\n",
    "\n",
    "df['max_authorship_count'] = (\n",
    "    df['authorship_counts']\n",
    "    .swifter\n",
    "    .apply(lambda counts: max(counts) if len(counts)>0 else 0)\n",
    ")\n",
    "\n",
    "df['max_recsys_authorship_count'] = (\n",
    "    df['recsys_authorship_counts']\n",
    "    .swifter\n",
    "    .apply(lambda counts: max(counts) if len(counts)>0 else 0)\n",
    ")\n",
    "\n",
    "df['sum_authorship_count'] = (\n",
    "    df['authorship_counts']\n",
    "    .swifter\n",
    "    .apply(lambda counts: sum(counts) if len(counts)>0 else 0)\n",
    ")\n",
    "\n",
    "df['sum_recsys_authorship_count'] = (\n",
    "    df['recsys_authorship_counts']\n",
    "    .swifter\n",
    "    .apply(lambda counts: sum(counts) if len(counts)>0 else 0)\n",
    ")\n",
    "\n",
    "(\n",
    "    (df['max_authorship_count']>0).mean(), df[df['max_authorship_count']>0]['max_authorship_count'].mean(),\n",
    "    (df['max_recsys_authorship_count']>0).mean(), df[df['max_recsys_authorship_count']>0]['max_recsys_authorship_count'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263072ef-3eca-4747-a7e5-7f654122ccc4",
   "metadata": {},
   "source": [
    "## RecSys Venue Counts\n",
    "How many candidate recsys papers have been published at a paper's venue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f0388-a65b-4e1d-a783-c92614826632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of recsys papers in each venue\n",
    "recsys_venue_counts = recsys_df.groupby('venue')['paperId'].nunique().dropna().drop('')\n",
    "\n",
    "df['recsys_venue_count'] = (\n",
    "    df['venue']\n",
    "    .swifter\n",
    "    .apply(lambda v: recsys_venue_counts.loc[v] if v in recsys_venue_counts.index else 0)\n",
    ")\n",
    "\n",
    "(df['recsys_venue_count']>0).mean(), df[(df['recsys_venue_count']>0)]['recsys_venue_count'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b23965-d7e3-47bf-ba18-66779079c88d",
   "metadata": {},
   "source": [
    "## RecSys Linked Papers\n",
    "Here we are looking at the papers that cite or are cited by RS papers and how often this happens. I had originally looked at refs and cites however there are lots of non-recsys papers that attract recsys cites which means we risk including non-recsys papers just because recsys papers cite them. Better to focus on refs only I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5be18-cbef-42dd-a84e-9efb726a0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_paper_ids = set(recsys_df['paperId'].unique())\n",
    "\n",
    "# A list of references that are RS papers.\n",
    "candidate_linked_papers = (\n",
    "    df['references']\n",
    "    .swifter\n",
    "    .apply(lambda refs: [\n",
    "        ref \n",
    "        for ref in refs\n",
    "        if ref in recsys_paper_ids\n",
    "    ])\n",
    ")\n",
    "\n",
    "len(candidate_linked_papers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a829819-3d7f-4e22-82d8-91277a1c5762",
   "metadata": {},
   "source": [
    "The linked candidates that have more than a minimum count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061110f-f065-46b0-b2b2-978a6c484869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_linked_count = 2\n",
    "\n",
    "candidate_linked_papers_counts = candidate_linked_papers.explode().dropna().value_counts()\n",
    "\n",
    "linked_paper_ids = set(candidate_linked_papers_counts[candidate_linked_papers_counts > min_linked_count].index)\n",
    "\n",
    "len(candidate_linked_papers_counts), len(linked_paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38195e9-9900-490b-98e9-0ce8b6e70825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recsys_linked_papers'] = candidate_linked_papers.swifter.apply(\n",
    "    lambda papers: [\n",
    "        paper \n",
    "        for paper in papers \n",
    "        if paper in linked_paper_ids\n",
    "    ]\n",
    ")\n",
    "\n",
    "df['num_recsys_linked_papers'] = df['recsys_linked_papers'].map(len)\n",
    "\n",
    "(df['num_recsys_linked_papers']>0).mean(), df[df['num_recsys_linked_papers']>0]['num_recsys_linked_papers'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c934d-6e82-463f-b787-3ebf31c00ca9",
   "metadata": {},
   "source": [
    "## Field of Study\n",
    "The Computer Science FoS might also be a useful feature to consider in our refinement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b65f4-dce1-47a8-9f2c-035d197c69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fos_contains_cs'] = df['fieldsOfStudy'].swifter.apply(lambda fos: 'Computer Science' in fos)\n",
    "df['fos_contains_cs'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a7dc0-378d-4c32-b999-5a1ae836c9e6",
   "metadata": {},
   "source": [
    "# The Rules for RecSys Papers\n",
    "Here is where we setup the various rules to use when determining whether a paper is a core RS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fe954-5e8e-4fdd-a6da-93038ed6a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_recsys_dblp_key = df['has_recsys_key']\n",
    "is_within_recsys_years = df['is_within_recsys_years']\n",
    "is_candidate_recsys_paper = df['is_candidate_recsys_paper']\n",
    "\n",
    "num_strong_recsys_phrases = df['num_strong_recsys_phrases']\n",
    "num_strong_recsys_phrases_in_title = df['num_strong_recsys_phrases_in_title']\n",
    "num_strong_recsys_phrases_in_venue = df['num_strong_recsys_phrases_in_venue']\n",
    "\n",
    "num_moderate_recsys_phrases = df['num_moderate_recsys_phrases']\n",
    "num_moderate_recsys_phrases_in_title = df['num_moderate_recsys_phrases_in_title']\n",
    "num_moderate_recsys_phrases_in_venue = df['num_moderate_recsys_phrases_in_venue']\n",
    "\n",
    "num_weak_recsys_phrases = df['num_weak_recsys_phrases']\n",
    "num_recsys_linked_papers = df['num_recsys_linked_papers']\n",
    "max_recsys_authorship_count = df['max_recsys_authorship_count']\n",
    "recsys_venue_count = df['recsys_venue_count']\n",
    "fos_contains_cs = df['fos_contains_cs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc2955-76bb-428c-bb3d-a73bda963edd",
   "metadata": {},
   "source": [
    "## For RecSys Candidates\n",
    "Apply these rules to papers that are already considered to be RS candidates. In other words, these are papers in our main dataset that have some evidence of being RS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f2057-62f7-4f30-8f62-44d65f4b3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_evidence_count = 5\n",
    "\n",
    "min_authorship_count = 3\n",
    "min_venue_count = 3\n",
    "weak_evidence_factor = 1.5\n",
    "\n",
    "# Is the abstract contains \"Recommendation System\" in title case then it can be\n",
    "# a reliable indication of a specific recommender system.\n",
    "has_system_evidence = df['abstract'].str.contains('Recommendation System')==True\n",
    "\n",
    "has_strong_evidence = (\n",
    "    (num_strong_recsys_phrases>0) | \n",
    "    (num_strong_recsys_phrases_in_venue>0) |\n",
    "    ((num_moderate_recsys_phrases_in_title>0) & is_within_recsys_years) |\n",
    "    ((num_moderate_recsys_phrases_in_venue>0) & is_within_recsys_years) | \n",
    "    (has_recsys_dblp_key)\n",
    ")\n",
    "\n",
    "# Is there a moderate recsys phrase and some additional evidence?\n",
    "has_moderate_evidence = (\n",
    "    (num_moderate_recsys_phrases>0) \n",
    "    & (\n",
    "        (num_recsys_linked_papers \n",
    "         + (max_recsys_authorship_count  >= min_authorship_count)\n",
    "         + (recsys_venue_count >= min_venue_count) \n",
    "         + fos_contains_cs\n",
    "        ) > min_evidence_count\n",
    "    )\n",
    ")\n",
    "\n",
    "# Is there a weak recsys phrase and some additional evidence?\n",
    "has_weak_evidence = (\n",
    "    (num_weak_recsys_phrases>0) \n",
    "    & (\n",
    "        (num_recsys_linked_papers \n",
    "         + (max_recsys_authorship_count  >= min_authorship_count) \n",
    "         + (recsys_venue_count >= min_venue_count) \n",
    "         + fos_contains_cs\n",
    "        ) > min_evidence_count*weak_evidence_factor\n",
    "    )\n",
    ")\n",
    "\n",
    "check_candidate_recsys_papers = (\n",
    "\n",
    "    # Its a canadiate recsys paper in the right time-frame ... \n",
    "    is_within_recsys_years & is_candidate_recsys_paper &\n",
    "\n",
    "    (has_system_evidence | has_strong_evidence | has_moderate_evidence | has_weak_evidence)\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "check_candidate_recsys_papers.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ef194-c6ec-4aac-9ac5-71876b319b4a",
   "metadata": {},
   "source": [
    "## For Non-Candidates\n",
    "We also reconsider other papers in our main dataset that are not currently RS canddiates. These are papers that have been included because they are linked to an RS paper (author pubs, refs, cites). There is at least a chance that some will be RS papers even though they were not found in our original search for RS papers. We require more evidence for these papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce979b8-d328-4db5-a3b8-849607a84cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Slightly higher min evidence count\n",
    "min_evidence_count = 6\n",
    "\n",
    "# weak_evidence_factor = 2\n",
    "\n",
    "# has_strong_evidence = (num_strong_recsys_phrases>0) | ((num_moderate_recsys_phrases_in_title>0) & is_within_recsys_years) | (has_recsys_dblp_key)\n",
    "\n",
    "has_strong_evidence = (\n",
    "    (num_strong_recsys_phrases>0) | \n",
    "    (num_strong_recsys_phrases_in_venue>0) |\n",
    "    ((num_moderate_recsys_phrases_in_title>0) & is_within_recsys_years) |\n",
    "    ((num_moderate_recsys_phrases_in_venue>0) & is_within_recsys_years) | \n",
    "    (has_recsys_dblp_key)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "has_moderate_evidence = (\n",
    "    (num_moderate_recsys_phrases>0) \n",
    "    & (\n",
    "        (num_recsys_linked_papers \n",
    "         + (max_recsys_authorship_count  >= min_authorship_count)\n",
    "         + (recsys_venue_count >= min_venue_count) \n",
    "         + fos_contains_cs\n",
    "        ) > min_evidence_count\n",
    "    )\n",
    ")\n",
    "\n",
    "has_weak_evidence = (\n",
    "    (num_weak_recsys_phrases>0) \n",
    "    & (\n",
    "        (num_recsys_linked_papers \n",
    "         + (max_recsys_authorship_count  >= min_authorship_count) \n",
    "         + (recsys_venue_count >= min_venue_count) \n",
    "         + fos_contains_cs\n",
    "        ) > min_evidence_count*weak_evidence_factor\n",
    "    )\n",
    ")\n",
    "\n",
    "check_non_candidate_recsys_papers = (\n",
    "\n",
    "    # Its a canadiate recsys paper in the right time-frame ... \n",
    "    is_within_recsys_years & (~is_candidate_recsys_paper) &\n",
    "\n",
    "    (has_system_evidence | has_strong_evidence | has_moderate_evidence | has_weak_evidence)\n",
    ")\n",
    "\n",
    "\n",
    "check_non_candidate_recsys_papers.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b533a0b-79d1-4241-ac48-c78fd7ee528a",
   "metadata": {},
   "source": [
    "## Mark the recommender systems papers\n",
    "Identify the papers that qualify after the above filters/rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f3773-f093-4da1-86e2-dc3ccd115a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_recsys_paper'] = np.where(check_candidate_recsys_papers | check_non_candidate_recsys_papers, True, False)\n",
    "df['is_recsys_paper'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a8a79-1d72-4a88-811c-3db6f796fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_recsys_paper_ids = ['51d267b782e7caf2b6bc7240b1a5f48044ffe115']\n",
    "\n",
    "df['is_recsys_paper'] = np.where(df['paperId'].isin(bad_recsys_paper_ids), False, df['is_recsys_paper'])\n",
    "\n",
    "df['is_recsys_paper'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866011fa-8f6f-4ef3-8508-31c151569631",
   "metadata": {},
   "source": [
    "# Mark Core RecSys Papers\n",
    "It is plausible that some of the papers we identify as RecSys papers are relevant but not core to the field. They might be papers on a technique that is called out as being relevant to recsys in the abstract, for example. So, let's try to identify the core recsys papers that are unabiguously about recsys. To do this we will include all recsys papers published in the core recsys venues (`has_recsys_key` is True) and also those that have a strong recsys phrase in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a284197-d09d-4a61-a298-effd780ec974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_contains_personalization_and_recommendation(title):\n",
    "    title = title.lower()\n",
    "\n",
    "    return ('personali' in title) & ('recommend' in title)\n",
    "\n",
    "has_title_contains_personalization_and_recommendation = df['title'].map(title_contains_personalization_and_recommendation)\n",
    "\n",
    "\n",
    "def title_ends_with_recommendation(title):\n",
    "\n",
    "    title = title.lower().replace('.', '')\n",
    "    last_word = title.split()[-1]\n",
    "\n",
    "    return (last_word=='recommendation') | (last_word=='recommendations')\n",
    "\n",
    "has_title_ends_with_recommendation = df['title'].map(title_ends_with_recommendation)\n",
    "\n",
    "\n",
    "def contains_recsys_phrase(title):\n",
    "\n",
    "    title = title.lower()\n",
    "\n",
    "    # A fairly accommodating set of terms but they have to be in the title and the papers\n",
    "    # will be recsys candidates to begin with.\n",
    "    strong_recsys_phrases = set([\n",
    "        'recommend',\n",
    "        'collaborative filter', 'information filter',\n",
    "        'recsys', 'movielens', 'grouplens', 'netflix prize', 'cold start', 'cold-start',\n",
    "    ])\n",
    "\n",
    "    for phrase in strong_recsys_phrases:\n",
    "        if phrase in title: return True\n",
    "\n",
    "    return False\n",
    "\n",
    "has_recsys_title = df['title'].map(contains_recsys_phrase)\n",
    "\n",
    "is_recsys_venue = df['num_strong_recsys_phrases_in_venue']>0\n",
    "contains_freq_recommender = df['text'].map(lambda text: text.count('recommender')>2)\n",
    "\n",
    "contains_recommendation_system = (\n",
    "    ((df['title'].map(lambda title:title.lower()).str.contains('recommend')) & (df['text'].map(lambda text: text.count('recommend')>1)))\n",
    "    | (df['text'].map(lambda text: text.count('recommend')>2))\n",
    ")\n",
    "\n",
    "is_recsys_paper = df['is_recsys_paper']\n",
    "has_recsys_key = df['has_recsys_key']\n",
    "\n",
    "recsys_venues = ['acm recsys', 'intrsrecsys', 'recsys poster', 'rectourrecsys', 'recsys challenge']\n",
    "in_recsys_venue = df['venue'].map(lambda venue: venue.lower()).isin(recsys_venues)\n",
    "\n",
    "is_within_recsys_years = df['year'].between(1990, 2023)\n",
    "\n",
    "# is_core_recsys_paper = has_recsys_key | (is_recsys_paper & has_recsys_title)\n",
    "\n",
    "is_core_recsys_paper = is_within_recsys_years & (\n",
    "    has_recsys_dblp_key |\n",
    "    (is_recsys_paper & has_title_ends_with_recommendation) |\n",
    "    (is_recsys_paper & has_title_contains_personalization_and_recommendation) | \n",
    "    (is_recsys_paper & has_recsys_title) | \n",
    "    (is_recsys_paper & is_recsys_venue) | \n",
    "    (is_recsys_paper & contains_freq_recommender) |\n",
    "    (is_recsys_paper & contains_recommendation_system)\n",
    ")\n",
    "\n",
    "df['is_core_recsys_paper'] = is_core_recsys_paper\n",
    "\n",
    "df['is_recsys_paper'].sum(), df['is_core_recsys_paper'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99f1b4-7f14-4a1f-ae1b-f01c10f048f9",
   "metadata": {},
   "source": [
    "# Save Refined RecSys Datasets\n",
    "At this point we have a refined dataset with a clearer separation between RS and non-RS papers. Save this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660f1b5-b74b-45d2-a090-7458834c0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(refined_recsys_papers_dataset)\n",
    "df.shape, refined_recsys_papers_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e189d-b56a-4004-9dfb-e2243afb5f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
