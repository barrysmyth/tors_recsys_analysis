{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8eeb31-7c25-41c5-acfe-be1960a920b7",
   "metadata": {},
   "source": [
    "# Emerging Topics\n",
    "In this notebook we perform and emerging topic analysis to identify those recent topics that exhibit the greatest momentum in terms of publication output and impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f5992-c77f-430b-a821-ab415d4071a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import string \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Stemmer\n",
    "\n",
    "import random\n",
    "import requests\n",
    "from itertools import chain\n",
    "from more_itertools import sliced\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.pylab import plt\n",
    "from matplotlib_venn import venn2, venn3\n",
    "import matplotlib as mpl\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import pyplot as plt, patches\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob, iglob\n",
    "from pathlib import Path\n",
    "                         \n",
    "from loguru import logger\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from itables import init_notebook_mode, show, options\n",
    "init_notebook_mode(all_interactive=False)\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('paper', font_scale=1.25)\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c37d8-365f-4812-9087-989945ee33c5",
   "metadata": {},
   "source": [
    "# Load the RecSys Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf240c-ae4b-44f9-ac8c-d153edcbbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_papers_df = pd.read_feather('../data/processed/3500_recsys_papers_with_influence_ranks.feather')\n",
    "\n",
    "recsys_papers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2cf42-35a2-44fc-afe3-a4e3f6ab698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_papers_df['bibtex_key'] = recsys_papers_df['bibtex'].map(\n",
    "    lambda bibtex: bibtex.split('{')[1].split(',')[0] if bibtex is not None else ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08f2ad-51f9-4573-93b2-89b8857e0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_by_topic_df = pd.read_feather('../data/processed/3410_papers_by_topic.feather')\n",
    "papers_by_topic_df[(papers_by_topic_df['growing_papers']) & (papers_by_topic_df['growing_citations'])].sort_values(by='momentum', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b4169-9728-43d3-956a-8bae8a4f38d0",
   "metadata": {},
   "source": [
    "# Emerging Topics Analysis\n",
    "Here we focus on recent topics with growing papers and citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44e6d3-1f35-4d36-ad5c-22366965b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_titles = recsys_papers_df['title'].map(lambda title: len(title.split())>2 if title is not None else '')\n",
    "with_authors = recsys_papers_df['author_names'].map(lambda a: len(a)>0 if a is not None else False)\n",
    "with_venues = recsys_papers_df['venue'].map(lambda v: len(v)>3 if v is not None else False)\n",
    "with_topic = recsys_papers_df['recsys_adj_topic_name'].notnull()\n",
    "\n",
    "\n",
    "# Based on the last 4 (2020-2023 inclusive) years to match up with how we calculated momentum in topics.\n",
    "is_emerging = recsys_papers_df['year'] >= 2020\n",
    "is_emerging.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba87a5f-9cf5-4733-8cdb-952f326fb612",
   "metadata": {},
   "source": [
    "## Main Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ecb7df-0326-462b-acc7-6a7ec326bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_papers = papers_by_topic_df['growing_papers'] = papers_by_topic_df['momentum_papers']>0\n",
    "growing_citations = papers_by_topic_df['growing_citations'] = papers_by_topic_df['momentum_citations']>0\n",
    "\n",
    "papers_by_topic_df['topic_age'] = 2024-papers_by_topic_df['threshold_year_papers']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "\n",
    "for name, data in papers_by_topic_df.iterrows():\n",
    "\n",
    "    x, y = data.filter(like='momentum_')\n",
    "\n",
    "    size_scale = 40\n",
    "    s = (data['num_papers']**1.3)/size_scale\n",
    "\n",
    "    age = data['topic_age']\n",
    "    norm = mpl.colors.Normalize(vmin=papers_by_topic_df['topic_age'].min(), vmax=papers_by_topic_df['topic_age'].max())\n",
    "    cmap = plt.get_cmap('coolwarm_r') \n",
    "    c = cmap(norm(age))\n",
    "\n",
    "    ax.scatter(x, y, marker='o', s=s, color=c, ec='k', lw=.5, alpha=.5)\n",
    "\n",
    "\n",
    "ax.axhline(0, lw=.5, ls='--', c='k', zorder=-100)\n",
    "ax.axvline(0, lw=.5, ls='--', c='k', zorder=-100)\n",
    "\n",
    "ax.set_xlabel('Publication Momentum')\n",
    "ax.set_ylabel('Citation Momentum')\n",
    "\n",
    "\n",
    "# Add manual annotations\n",
    "fontsize = 10\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Graph, Knowledge, Items, Network'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x-.3, y, 'Graph, Knowledge ({:.0f})'.format(year), ha='right', va='center')\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Fairness, Bias, Unfairness, Gender'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x, y, '  Fairness, Bias ({:.0f})'.format(year), ha='left', va='center')\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Crop, Soil, Agricultural, Farmers'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x, y, '  Crop, Soil ({:.0f})'.format(year), ha='left', va='center')\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Session, Sequential, Items, Model'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x-.3, y-.01, 'Session, Sequential ({:.0f})'.format(year), ha='right', va='center')\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Conversational, Explanations, User, Dialogue'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x+.3, y, 'Conversational, Explanation ({:.0f})'.format(year), ha='left', va='center')\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Learning, Reinforcement, Bandit, User'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x-.3, y, 'Learning, Reinforcement ({:.0f})'.format(year), ha='right', va='center')\n",
    "\n",
    "x, y, year = papers_by_topic_df.loc['Deep, Neural, Learning, Model'][['momentum_papers', 'momentum_citations', 'threshold_year_papers']]\n",
    "ax.text(x+.3, y, 'Deep, Neural ({:.0f})'.format(year), ha='left', va='center')\n",
    "\n",
    "sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cax = fig.add_axes([1, .12, 0.03, .85])\n",
    "cbar = plt.colorbar(sm, cax=cax, alpha=.5)\n",
    "cbar.set_label('Topic Age')\n",
    "\n",
    "\n",
    "\n",
    "if (growing_citations & ~growing_papers).sum()>0:\n",
    "    ax.text(-1.5, 6, '{:.0f} topics ({:.1f}±{:.1f}, {:.1f}±{:.1f})'.format(\n",
    "        (growing_citations & ~growing_papers).sum(), \n",
    "        *papers_by_topic_df[growing_citations & ~growing_papers].filter(like='momentum_').agg(['mean', 'std']).T.values.flatten()), \n",
    "        ha='left', fontstyle='italic', bbox=dict(boxstyle='round', lw=.5, facecolor='w', alpha=1))\n",
    "\n",
    "if (growing_citations & growing_papers).sum()>0:\n",
    "    ax.text(6.25, 6, '{:.0f} topics ({:.1f}±{:.1f}, {:.1f}±{:.1f})'.format(\n",
    "        (growing_citations & growing_papers).sum(), \n",
    "        *papers_by_topic_df[growing_citations & growing_papers].filter(like='momentum_').agg(['mean', 'std']).T.values.flatten()),\n",
    "        ha='right', fontstyle='italic', bbox=dict(boxstyle='round', lw=.5, facecolor='w', alpha=1))\n",
    "\n",
    "if (~growing_citations & growing_papers).sum()>0:\n",
    "    ax.text(6.25, -1.6, '{:.0f} topics ({:.1f}±{:.1f}, {:.1f}±{:.1f})'.format(\n",
    "        (~growing_citations & growing_papers).sum(), \n",
    "        *papers_by_topic_df[~growing_citations & growing_papers].filter(like='momentum_').agg(['mean', 'std']).T.values.flatten()),\n",
    "        ha='right', fontstyle='italic', bbox=dict(boxstyle='round', lw=.5, facecolor='w', alpha=1))\n",
    "\n",
    "if (~growing_citations & ~growing_papers).sum()>0:\n",
    "    ax.text(-1.8, -1.6, '{:.0f} topics\\n({:.1f}±{:.1f}, {:.1f}±{:.1f})'.format(\n",
    "        (~growing_citations & ~growing_papers).sum(), \n",
    "        *papers_by_topic_df[~growing_citations & ~growing_papers].filter(like='momentum_').agg(['mean', 'std']).T.values.flatten()),\n",
    "        ha='left', fontstyle='italic', bbox=dict(boxstyle='round', lw=.5, facecolor='w', alpha=1))\n",
    "\n",
    "\n",
    "ax.set_xlim(-1.99, 6.5)\n",
    "ax.set_ylim(-1.99, 6.5)\n",
    "\n",
    "\n",
    "growth_rect = patches.Rectangle((0, 0), 6.5, 6.5, facecolor=\"whitesmoke\", linewidth=0, zorder=-100, alpha=.5)\n",
    "ax.add_patch(growth_rect)\n",
    "\n",
    "contract_rect = patches.Rectangle((-2, -2), 2, 2, facecolor=\"whitesmoke\", linewidth=0, zorder=-100, alpha=.5)\n",
    "ax.add_patch(contract_rect)\n",
    "\n",
    "stable_rect = patches.Rectangle((-1, -1), 2, 2, facecolor='none', ec='k', ls=':', linewidth=.5)\n",
    "ax.add_patch(stable_rect)\n",
    "\n",
    "ax.plot(ax.get_xlim(), ax.get_ylim(), lw=.5, ls='--', c='k', zorder=-100)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('../graphs/3600_recsys_emerging_topics.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c5720-afcf-4069-8a6f-3e4abb5cfa3f",
   "metadata": {},
   "source": [
    "## The Emerging Topics & Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0ac9f-e71a-4d0b-9a77-fa4e5a014c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_by_topic_df['momentum'] = ((papers_by_topic_df['momentum_citations']**2) + (papers_by_topic_df['momentum_papers']**2)).map(np.sqrt)\n",
    "\n",
    "emerging_topics = papers_by_topic_df['momentum']>2**.5\n",
    "\n",
    "sorted_emerging_topics_df = papers_by_topic_df[emerging_topics].sort_values(by='momentum', ascending=False)\n",
    "\n",
    "sorted_emerging_topics_df.filter(like='momentum').agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7faf0-060b-40fe-bd95-5313e8a9881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_papers_by_id = recsys_papers_df.set_index('paperId')\n",
    "\n",
    "emerging_papers_df = recsys_papers_by_id.loc[list(sorted_emerging_topics_df['papers'].explode().dropna().values)]\n",
    "emerging_papers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b345af-a5e4-4029-abf9-323e0c02ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_threshold_year = emerging_papers_df.swifter.apply(lambda paper: paper['year']>=papers_by_topic_df.loc[paper['recsys_adj_topic_name']]['threshold_year_papers'], axis=1)\n",
    "after_threshold_year.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec01b00-fca9-4913-8cdc-54e78cf3bf65",
   "metadata": {},
   "source": [
    "## Top Paper for each Emerging Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a8a18-1bfb-4598-9096-70f1f6137237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_papers_table(top_papers):\n",
    "\n",
    "    top_papers = top_papers[['recsys_adj_topic_name', 'year', 'title', 'author_names', 'citationCount', 'bibtex_key']].copy()\n",
    "\n",
    "    top_papers['recsys_adj_topic_name'] = top_papers['recsys_adj_topic_name'].map(lambda topic: ', '.join([term for term in topic.split(', ')[:-2]]))\n",
    "    top_papers['year'] = top_papers['year'].map(int)\n",
    "\n",
    "    top_papers['title'] = (\n",
    "        top_papers['title'].map(lambda title: title[:65]+' ...') \n",
    "        + top_papers['bibtex_key'].map(lambda key: '\\cite{{{}}}'.format(key))\n",
    "    )\n",
    "    \n",
    "    # Just take the surnames to save space.\n",
    "    top_papers['author_names'] =  top_papers['author_names'].map(lambda author_names: author_names[0].split()[-1]+' et al.' if len(author_names)>1 else author_names[0].split()[-1])\n",
    "    top_papers['citationCount'] = top_papers['citationCount'].map(lambda count: '{:,.0f}'.format(count))\n",
    "\n",
    "    top_papers = top_papers[['recsys_adj_topic_name', 'year', 'title', 'author_names', 'citationCount']]\n",
    "    top_papers.columns = ['Topic', 'Year', 'Title', 'Authors', 'Cites']\n",
    "    top_papers.index = range(1, len(top_papers)+1)\n",
    "\n",
    "    return top_papers\n",
    "    \n",
    "    \n",
    "top_emerging_paper_by_topic_df = (\n",
    "    emerging_papers_df[emerging_papers_df['year']>=2020]\n",
    "    .sort_values(by='citationCount', ascending=False)\n",
    "    .groupby('recsys_adj_topic_name')\n",
    "    .apply(lambda g: g.head(3))\n",
    "    .sort_values(by='citationCount', ascending=False)\n",
    ")\n",
    "\n",
    "top_emerging_papers_table = top_papers_table(top_emerging_paper_by_topic_df).set_index('Year')\n",
    "top_emerging_papers_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186f6bb-54c5-4eea-866a-354b4dbdfae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_emerging_papers_table.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a8a15-48a9-4ec2-9cb0-664b0c9eae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(top_emerging_paper_by_topic_df['bibtex'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084a7d2-de9e-4fbe-9901-3ac062c9301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    len(emerging_papers_df[after_threshold_year]),\n",
    "    len(recsys_papers_df[recsys_papers_df['year']>=emerging_papers_df[after_threshold_year]['year'].min()]),\n",
    "    len(emerging_papers_df[after_threshold_year])/len(recsys_papers_df[recsys_papers_df['year']>=emerging_papers_df[after_threshold_year]['year'].min()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595f81b-182a-4755-8d18-6f2cdfb4d3b2",
   "metadata": {},
   "source": [
    "# Emerging Topic Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a00066-f327-4f97-863c-0fff1249fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS.add('facctrec')\n",
    "STOPWORDS.add('dialog')\n",
    "\n",
    "\n",
    "unique_tokens_by_topic = emerging_papers_df.groupby('recsys_adj_topic_name').apply(\n",
    "    lambda g: [token \n",
    "               for token in np.unique(np.concatenate(g['reversed_text_tokens'].values))\n",
    "               if (not(token.isdigit())) & (not(bool(re.search(r'\\d', token)))) & (not(token in STOPWORDS))\n",
    "              ]\n",
    ").explode().dropna()\n",
    "\n",
    "\n",
    "unique_tokens_by_topic_value_counts = unique_tokens_by_topic.value_counts()      \n",
    "\n",
    "allowed_tokens = set(unique_tokens_by_topic_value_counts[unique_tokens_by_topic_value_counts.between(0, 6)].index)\n",
    "len(allowed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293def2-1ddd-46a1-adce-4910e990ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wordcloud(ax, papers, col):\n",
    "\n",
    "    text = ' '.join([\n",
    "        word for word in ' '.join(papers[col].values).lower().split()\n",
    "        if word in allowed_tokens\n",
    "    ])\n",
    "    \n",
    "    wc = WordCloud(\n",
    "        width=500, height=500,\n",
    "        prefer_horizontal=0.33,\n",
    "        min_font_size=12, max_font_size=96,\n",
    "        background_color='white', colormap='twilight',\n",
    "        relative_scaling=0  # Use ranks only for scaling\n",
    "        ).generate_from_text(text)\n",
    "        \n",
    "    ax.imshow(wc, interpolation=\"bilinear\")\n",
    "\n",
    "    # ax.axis(\"off\")\n",
    "\n",
    "    ax.set_xlim(-20, 520)\n",
    "    ax.set_ylim(520, -20)\n",
    "    \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.tick_params('both', length=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebe884-03f7-4af1-86d3-0bc851013228",
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging_papers_df['recsys_adj_topic_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2af207-97cc-4404-83fa-cd5d7cfe59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_by_emerging_topic = emerging_papers_df[after_threshold_year].reset_index().groupby('recsys_adj_topic_name')['paperId'].apply(lambda g: g.values)\n",
    "\n",
    "\n",
    "# ncols = 7\n",
    "# nrows = (len(papers_by_emerging_topic)//ncols) if len(papers_by_emerging_topic)%ncols==0 else (len(papers_by_emerging_topic)//ncols)+1\n",
    "# s = 3\n",
    "\n",
    "# fig, axs = plt.subplots(figsize=(ncols*s, nrows*s), nrows=nrows, ncols=ncols, gridspec_kw=dict(wspace=.15, hspace=.5))\n",
    "# axs = axs.flatten()\n",
    "\n",
    "\n",
    "\n",
    "ncols = 4\n",
    "# nrows = (len(papers_by_emerging_topic)//ncols) if len(papers_by_emerging_topic)%ncols==0 else (len(papers_by_emerging_topic)//ncols)+1\n",
    "nrows = 2\n",
    "s = 2.5\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(ncols*s, nrows*s), nrows=nrows, ncols=ncols, gridspec_kw=dict(wspace=0, hspace=.3))\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "recsys_papers_by_id = recsys_papers_df.set_index('paperId')\n",
    "\n",
    "for ax, topic_name in zip(axs, emerging_papers_df.groupby('recsys_adj_topic_name').size().sort_values(ascending=False).index):\n",
    "    papers = recsys_papers_by_id.loc[papers_by_emerging_topic.loc[topic_name]]\n",
    "\n",
    "    recent_frac_inside = (papers['paper_type']=='inside').sum()/(emerging_papers_df[after_threshold_year]['paper_type']=='inside').sum()\n",
    "    recent_frac_outside = (papers['paper_type']=='outside').sum()/(emerging_papers_df[after_threshold_year]['paper_type']=='outside').sum()\n",
    "    recent_inside_bias = recent_frac_inside/(recent_frac_inside+recent_frac_outside)\n",
    "    \n",
    "    draw_wordcloud(ax, papers, 'title')\n",
    "\n",
    "    title = ', '.join(topic_name.split(', ')[:2])\n",
    "    if len(title)>18:\n",
    "        title = title[:18]+'...'\n",
    "\n",
    "    title += '\\n({:,}, {:,}, {:.1f})'.format(len(papers), papers['citationCount'].sum(), recent_inside_bias)\n",
    "\n",
    "    ax.set_title(title, fontsize=10, ha='center')\n",
    "\n",
    "    # Remove the empty graphs.\n",
    "    num_empty = (ncols*nrows)-len(papers_by_emerging_topic)\n",
    "    if num_empty>0:\n",
    "        for ax in axs[-num_empty:]: ax.axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('../graphs/3600_emerging_topic_word_clouds.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
